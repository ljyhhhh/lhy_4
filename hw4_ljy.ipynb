{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport torch\nimport random\nfrom pathlib import Path\nfrom torch.utils.data import Dataset\nfrom torch.nn.utils.rnn import pad_sequence\n \nclass myDataset(Dataset):\n    def __init__(self, data_dir, segment_len=128):\n        self.data_dir = data_dir\n        self.segment_len = segment_len\n \n    # Load the mapping from speaker neme to their corresponding id. \n        mapping_path = Path(data_dir) / \"mapping.json\"\n        mapping = json.load(mapping_path.open())\n        self.speaker2id = mapping[\"speaker2id\"]\n \n    # Load metadata of training data.\n        metadata_path = Path(data_dir) / \"metadata.json\"\n        metadata = json.load(open(metadata_path))[\"speakers\"]\n \n    # Get the total number of speaker.\n        self.speaker_num = len(metadata.keys())\n        self.data = []\n        for speaker in metadata.keys():\n            for utterances in metadata[speaker]:\n                self.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n \n    def __len__(self):\n        return len(self.data)\n \n    def __getitem__(self, index):\n        feat_path, speaker = self.data[index]\n    # Load preprocessed mel-spectrogram.\n        mel = torch.load(os.path.join(self.data_dir, feat_path))\n \n    # Segmemt mel-spectrogram into \"segment_len\" frames.\n        if len(mel) > self.segment_len:\n      # Randomly get the starting point of the segment.\n            start = random.randint(0, len(mel) - self.segment_len)\n      # Get a segment with \"segment_len\" frames.\n            mel = torch.FloatTensor(mel[start:start+self.segment_len])\n        else:\n            mel = torch.FloatTensor(mel)\n    # Turn the speaker id into long for computing loss later.\n        speaker = torch.FloatTensor([speaker]).long()\n        return mel, speaker\n    \n    def get_speaker_number(self):\n        return self.speaker_num","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.nn.utils.rnn import pad_sequence\n\n\ndef collate_batch(batch):\n  # Process features within a batch.\n \n    mel, speaker = zip(*batch)\n  # Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n    mel = pad_sequence(mel, batch_first=True, padding_value=-20)    # pad log 10^(-20) which is very small value.\n  # mel: (batch size, length, 40)\n    return mel, torch.FloatTensor(speaker).long()\n\n\ndef get_dataloader(data_dir, batch_size, n_workers):\n    \n    dataset = myDataset(data_dir)\n    speaker_num = dataset.get_speaker_number()\n  # Split dataset into training dataset and validation dataset\n    trainlen = int(0.9 * len(dataset))\n    \n    lengths = [trainlen, len(dataset) - trainlen]\n    trainset, validset = random_split(dataset, lengths)\n    \n    train_loader = DataLoader(\n    trainset,\n    batch_size=batch_size,\n    shuffle=True,\n    drop_last=True,\n    num_workers=n_workers,\n    pin_memory=True,\n    collate_fn=collate_batch,\n  )\n    \n    valid_loader = DataLoader(\n    validset,\n    batch_size=batch_size,\n    num_workers=n_workers,\n    drop_last=True,\n    pin_memory=True,\n    collate_fn=collate_batch,\n  )\n    print(\"train_set:\",len(trainset),\"valid_set:\",len(validset))\n    return train_loader, valid_loader, speaker_num\n\n\ntrain_loader,valid_loader,speaker_num=get_dataloader(\"/kaggle/input/dataset2/Dataset\",32,2)\nprint(\"speaker_num:\",speaker_num)\n# trainloader shape:[32,128,40]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom einops import rearrange\nfrom einops.layers.torch import Rearrange\n\nclass Swish(nn.Module):\n    def forward(self, x):\n        return x * x.sigmoid()\n\nclass ConformerBlock(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ff=nn.Sequential(\n            nn.Linear(80,320),\n            nn.ReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(320,80),\n            nn.ReLU(),\n            nn.Dropout(p=0.1)\n        )\n        self.atten=nn.TransformerEncoderLayer(\n      d_model=80, dim_feedforward=256, nhead=1\n    ) \n        self.conv=nn.Sequential(\n            nn.LayerNorm(80),\n            Rearrange('b n c -> b c n'),\n            nn.Conv1d(80,160,1,1),\n            nn.GLU(dim=1),\n            Rearrange('b c n -> b n c'),\n            nn.Conv1d(128,128,1,1),\n            Rearrange('b n c -> b c n'),\n            Swish(),\n            nn.Conv1d(80,80,1,1),\n            Rearrange('b c n -> b n c'),\n            nn.Dropout(p=0.1)\n        )\n        self.norm = nn.LayerNorm(80)\n    def forward(self,x):\n        x=0.5*self.ff(x)+x\n        x=self.atten(x).transpose(0, 1)+x.transpose(0, 1)\n        x=self.conv(x)+x\n        x=0.5*self.ff(x)+x\n        x=self.norm(x)\n        return x\n    \nclass Classifier(nn.Module):\n    def __init__(self, d_model=80, n_spks=600, dropout=0.1):\n        super().__init__()\n    # Project the dimension of features from that of input into d_model.\n        self.prenet = nn.Linear(40, d_model)\n    # TODO:\n    #   Change Transformer to Conformer.\n    #   https://arxiv.org/abs/2005.08100\n        self.encoder_layer = nn.TransformerEncoderLayer(\n      d_model=d_model, dim_feedforward=256, nhead=1\n    )\n        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n        self.conformer=ConformerBlock()\n    # Project the the dimension of features from d_model into speaker nums.\n        self.pred_layer = nn.Sequential(\n      #nn.Linear(d_model, d_model),\n      #nn.ReLU(),\n      nn.Linear(d_model, n_spks),\n    )\n\n    def forward(self, mels):\n   \n    # out: (batch size, length, d_model)\n        out = self.prenet(mels)\n    # out: (length, batch size, d_model)\n        out = out.permute(1, 0, 2)\n    # The encoder layer expect features in the shape of (length, batch size, d_model).\n        out = self.conformer(out)\n    # out: (batch size, length, d_model)\n        \n        stats = out.mean(dim=1)\n\n    # out: (batch, n_spks)\n        out = self.pred_layer(stats)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-01-06T04:19:05.804148Z","iopub.execute_input":"2023-01-06T04:19:05.804909Z","iopub.status.idle":"2023-01-06T04:19:05.821558Z","shell.execute_reply.started":"2023-01-06T04:19:05.804867Z","shell.execute_reply":"2023-01-06T04:19:05.820401Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import math\n\nimport torch\nfrom torch.optim import Optimizer\nfrom torch.optim.lr_scheduler import LambdaLR\n\n\ndef get_cosine_schedule_with_warmup(\n        optimizer: Optimizer,\n        num_warmup_steps: int,\n        num_training_steps: int,\n        num_cycles: float = 0.5,\n        last_epoch: int = -1\n):\n    def lr_lambda(current_step):\n        # warmup\n        if current_step < num_warmup_steps:\n            return float(current_step) / float(max(1, num_warmup_steps))\n        # decadence\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n\n    return LambdaLR(optimizer, lr_lambda, last_epoch)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-06T04:19:07.413230Z","iopub.execute_input":"2023-01-06T04:19:07.414051Z","iopub.status.idle":"2023-01-06T04:19:07.422787Z","shell.execute_reply.started":"2023-01-06T04:19:07.414015Z","shell.execute_reply":"2023-01-06T04:19:07.421461Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import torch\n\n\ndef model_fn(batch, model, criterion, device):\n  \n    mels, labels = batch\n    mels = mels.to(device)\n    labels = labels.to(device)\n\n    outs = model(mels)\n\n    loss = criterion(outs, labels)\n\n  # Get the speaker id with highest probability.\n    preds = outs.argmax(1)\n  # Compute accuracy.\n    accuracy = torch.mean((preds == labels).float())\n\n    return loss, accuracy\n\nfrom tqdm import tqdm\nimport torch\ndef valid(dataloader, model, criterion, device): \n  \n\n    model.eval()\n    running_loss = 0.0\n    running_accuracy = 0.0\n   \n    for i, batch in enumerate(dataloader):\n        with torch.no_grad():\n            loss, accuracy = model_fn(batch, model, criterion, device)\n            running_loss += loss.item()\n            running_accuracy += accuracy.item()\n\n    model.train()\n\n    return running_accuracy / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-01-06T04:19:08.917502Z","iopub.execute_input":"2023-01-06T04:19:08.917854Z","iopub.status.idle":"2023-01-06T04:19:08.927120Z","shell.execute_reply.started":"2023-01-06T04:19:08.917824Z","shell.execute_reply":"2023-01-06T04:19:08.926066Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader, random_split\nimport matplotlib.pyplot as plt\n\n\ndef parse_args():\n    config = {\n    \"data_dir\": \"/kaggle/input/dataset2/Dataset\",\n    \"save_path\": \"model.ckpt\",\n    \"batch_size\": 32,\n    \"n_workers\": 8,\n    \"valid_steps\": 2000,\n    \"warmup_steps\": 1000,\n    \"save_steps\": 10000,\n    \"total_steps\": 100001,\n  }\n\n    return config\n\ntrain_acc_list=[]\nval_acc_list=[]\n\ndef main(\n  data_dir,\n  save_path,\n  batch_size,\n  n_workers,\n  valid_steps,\n  warmup_steps,\n  total_steps,\n  save_steps,\n):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"[Info]: Use {device} now!\")\n\n    train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n    train_iterator = iter(train_loader)\n    print(f\"[Info]: Finish loading data!\",flush = True)\n\n    model = Classifier(n_spks=speaker_num).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = AdamW(model.parameters(), lr=1e-3)\n    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n    print(f\"[Info]: Finish creating model!\",flush = True)\n\n    best_accuracy = -1.0\n    best_state_dict = None\n\n    \n    batch_accuracy=0.0\n    for step in range(total_steps):\n    # Get data\n        try:\n            batch = next(train_iterator)\n        except StopIteration:\n            train_iterator = iter(train_loader)\n            batch = next(train_iterator)\n\n        loss, accuracy = model_fn(batch, model, criterion, device)\n        batch_loss = loss.item()\n        batch_accuracy += accuracy.item()\n        if(step%1000==0 and step!=0 ):\n            batch_accuracy/=1000\n            print(int(step/1000),\"/100,train_acc:\",batch_accuracy)\n            train_acc_list.append(batch_accuracy)\n            batch_accuracy=0\n            \n        \n    # Updata model\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n    \n    \n        \n    # Do validation\n        if step  % 1000 == 0 and step!=0 :\n            valid_accuracy = valid(valid_loader, model, criterion, device)\n            print(\"val_acc:\",valid_accuracy)\n            val_acc_list.append(valid_accuracy)\n            if valid_accuracy > best_accuracy:\n                best_accuracy = valid_accuracy\n                best_state_dict = model.state_dict()\n\n            \n    # Save the best model so far.\n        if (step + 1) % save_steps == 0 and best_state_dict is not None:\n            torch.save(best_state_dict, save_path)\n    plt.figure()\n    x=range(0,100)\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"acc\")\n    plt.plot(x,train_acc_list,color='g',label='train_acc')\n    plt.plot(x,val_acc_list,color='r',label='val_acc')\n    plt.legend()\n    plt.show()\nif __name__ == \"__main__\":\n    main(**parse_args())","metadata":{"execution":{"iopub.status.busy":"2023-01-06T06:01:22.832808Z","iopub.execute_input":"2023-01-06T06:01:22.833644Z","iopub.status.idle":"2023-01-06T06:55:40.534666Z","shell.execute_reply.started":"2023-01-06T06:01:22.833571Z","shell.execute_reply":"2023-01-06T06:55:40.533387Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"[Info]: Use cuda now!\ntrain_set: 62494 valid_set: 6944\n[Info]: Finish loading data!\n[Info]: Finish creating model!\n1 /100,train_acc: 0.04265625\nval_acc: 0.10555875576036866\n2 /100,train_acc: 0.1755\nval_acc: 0.2436635944700461\n3 /100,train_acc: 0.2845625\nval_acc: 0.3201324884792627\n4 /100,train_acc: 0.34125\nval_acc: 0.388536866359447\n5 /100,train_acc: 0.39421875\nval_acc: 0.4099942396313364\n6 /100,train_acc: 0.4295625\nval_acc: 0.44772465437788017\n7 /100,train_acc: 0.4550625\nval_acc: 0.46327764976958524\n8 /100,train_acc: 0.48328125\nval_acc: 0.4870391705069124\n9 /100,train_acc: 0.50475\nval_acc: 0.5\n10 /100,train_acc: 0.516875\nval_acc: 0.5252016129032258\n11 /100,train_acc: 0.53609375\nval_acc: 0.536434331797235\n12 /100,train_acc: 0.551625\nval_acc: 0.5429147465437788\n13 /100,train_acc: 0.56503125\nval_acc: 0.5652361751152074\n14 /100,train_acc: 0.578375\nval_acc: 0.5734447004608295\n15 /100,train_acc: 0.5874375\nval_acc: 0.5891417050691244\n16 /100,train_acc: 0.59696875\nval_acc: 0.5859735023041475\n17 /100,train_acc: 0.60971875\nval_acc: 0.5910138248847926\n18 /100,train_acc: 0.6188125\nval_acc: 0.5944700460829493\n19 /100,train_acc: 0.62515625\nval_acc: 0.6175115207373272\n20 /100,train_acc: 0.63871875\nval_acc: 0.6244239631336406\n21 /100,train_acc: 0.64178125\nval_acc: 0.6298963133640553\n22 /100,train_acc: 0.65015625\nval_acc: 0.621831797235023\n23 /100,train_acc: 0.6534375\nval_acc: 0.6394009216589862\n24 /100,train_acc: 0.66440625\nval_acc: 0.6286002304147466\n25 /100,train_acc: 0.66453125\nval_acc: 0.6466013824884793\n26 /100,train_acc: 0.67478125\nval_acc: 0.6359447004608295\n27 /100,train_acc: 0.67965625\nval_acc: 0.6589861751152074\n28 /100,train_acc: 0.68571875\nval_acc: 0.659418202764977\n29 /100,train_acc: 0.6898125\nval_acc: 0.6535138248847926\n30 /100,train_acc: 0.7019375\nval_acc: 0.6683467741935484\n31 /100,train_acc: 0.7008125\nval_acc: 0.6702188940092166\n32 /100,train_acc: 0.7116875\nval_acc: 0.6761232718894009\n33 /100,train_acc: 0.70684375\nval_acc: 0.675979262672811\n34 /100,train_acc: 0.721125\nval_acc: 0.6792914746543779\n35 /100,train_acc: 0.7224375\nval_acc: 0.6792914746543779\n36 /100,train_acc: 0.72984375\nval_acc: 0.6964285714285714\n37 /100,train_acc: 0.7268125\nval_acc: 0.6877880184331797\n38 /100,train_acc: 0.73621875\nval_acc: 0.6860599078341014\n39 /100,train_acc: 0.735\nval_acc: 0.7044930875576036\n40 /100,train_acc: 0.7458125\nval_acc: 0.7088133640552995\n41 /100,train_acc: 0.7478125\nval_acc: 0.7125576036866359\n42 /100,train_acc: 0.75484375\nval_acc: 0.7023329493087558\n43 /100,train_acc: 0.75375\nval_acc: 0.7118375576036866\nval_acc: 0.7191820276497696\n45 /100,train_acc: 0.75459375\nval_acc: 0.7160138248847926\n46 /100,train_acc: 0.77084375\nval_acc: 0.7148617511520737\n47 /100,train_acc: 0.76871875\nval_acc: 0.7210541474654378\n48 /100,train_acc: 0.77221875\nval_acc: 0.7243663594470046\n49 /100,train_acc: 0.778\nval_acc: 0.7370391705069125\n50 /100,train_acc: 0.77971875\nval_acc: 0.7285426267281107\n51 /100,train_acc: 0.78603125\nval_acc: 0.7435195852534562\n52 /100,train_acc: 0.78828125\nval_acc: 0.7295506912442397\n53 /100,train_acc: 0.788625\nval_acc: 0.7423675115207373\n54 /100,train_acc: 0.7928125\nval_acc: 0.7432315668202765\n55 /100,train_acc: 0.798375\nval_acc: 0.7484158986175116\n56 /100,train_acc: 0.79996875\nval_acc: 0.7459677419354839\n57 /100,train_acc: 0.80234375\nval_acc: 0.7595046082949308\n58 /100,train_acc: 0.80890625\nval_acc: 0.7481278801843319\n59 /100,train_acc: 0.80853125\nval_acc: 0.7517281105990783\n60 /100,train_acc: 0.81553125\nval_acc: 0.7613767281105991\n61 /100,train_acc: 0.8136875\nval_acc: 0.7527361751152074\n62 /100,train_acc: 0.82053125\nval_acc: 0.7595046082949308\n63 /100,train_acc: 0.82540625\nval_acc: 0.7645449308755761\n64 /100,train_acc: 0.8220625\nval_acc: 0.7655529953917051\n65 /100,train_acc: 0.830875\nval_acc: 0.7655529953917051\n66 /100,train_acc: 0.8301875\nval_acc: 0.7720334101382489\n67 /100,train_acc: 0.8316875\nval_acc: 0.7741935483870968\n68 /100,train_acc: 0.83403125\nval_acc: 0.7645449308755761\n69 /100,train_acc: 0.83865625\nval_acc: 0.7703052995391705\n70 /100,train_acc: 0.83746875\nval_acc: 0.7684331797235023\n71 /100,train_acc: 0.84475\nval_acc: 0.7741935483870968\n72 /100,train_acc: 0.842\nval_acc: 0.7783698156682027\n73 /100,train_acc: 0.84759375\nval_acc: 0.7800979262672811\n74 /100,train_acc: 0.84853125\nval_acc: 0.7800979262672811\n75 /100,train_acc: 0.8519375\nval_acc: 0.779089861751152\n76 /100,train_acc: 0.84953125\nval_acc: 0.7867223502304147\n77 /100,train_acc: 0.85478125\nval_acc: 0.7816820276497696\n78 /100,train_acc: 0.85571875\nval_acc: 0.7772177419354839\n79 /100,train_acc: 0.86115625\nval_acc: 0.7825460829493087\n80 /100,train_acc: 0.85975\nval_acc: 0.7874423963133641\n81 /100,train_acc: 0.861875\nval_acc: 0.7996831797235023\n82 /100,train_acc: 0.863875\nval_acc: 0.7821140552995391\n83 /100,train_acc: 0.8663125\nval_acc: 0.8001152073732719\n84 /100,train_acc: 0.86446875\nval_acc: 0.7962269585253456\n85 /100,train_acc: 0.8705625\nval_acc: 0.7962269585253456\n86 /100,train_acc: 0.86715625\nval_acc: 0.7998271889400922\n87 /100,train_acc: 0.87040625\nval_acc: 0.7962269585253456\n88 /100,train_acc: 0.8746875\nval_acc: 0.7976670506912442\n89 /100,train_acc: 0.875\nval_acc: 0.7983870967741935\n90 /100,train_acc: 0.87359375\nval_acc: 0.7992511520737328\n91 /100,train_acc: 0.87375\nval_acc: 0.8034274193548387\n92 /100,train_acc: 0.873\nval_acc: 0.7933467741935484\n93 /100,train_acc: 0.875375\nval_acc: 0.8025633640552995\n94 /100,train_acc: 0.87928125\nval_acc: 0.8008352534562212\n95 /100,train_acc: 0.8784375\nval_acc: 0.7980990783410138\n96 /100,train_acc: 0.87496875\nval_acc: 0.7963709677419355\n97 /100,train_acc: 0.87834375\nval_acc: 0.8008352534562212\n98 /100,train_acc: 0.8794375\nval_acc: 0.794786866359447\n99 /100,train_acc: 0.8791875\nval_acc: 0.8029953917050692\n100 /100,train_acc: 0.87625\nval_acc: 0.8063076036866359\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}