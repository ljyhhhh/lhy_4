{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    " \n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, data_dir, segment_len=128):\n",
    "        self.data_dir = data_dir\n",
    "        self.segment_len = segment_len\n",
    " \n",
    "    # Load the mapping from speaker neme to their corresponding id. \n",
    "        mapping_path = Path(data_dir) / \"mapping.json\"\n",
    "        mapping = json.load(mapping_path.open())\n",
    "        self.speaker2id = mapping[\"speaker2id\"]\n",
    " \n",
    "    # Load metadata of training data.\n",
    "        metadata_path = Path(data_dir) / \"metadata.json\"\n",
    "        metadata = json.load(open(metadata_path))[\"speakers\"]\n",
    " \n",
    "    # Get the total number of speaker.\n",
    "        self.speaker_num = len(metadata.keys())\n",
    "        self.data = []\n",
    "        for speaker in metadata.keys():\n",
    "            for utterances in metadata[speaker]:\n",
    "                self.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        feat_path, speaker = self.data[index]\n",
    "    # Load preprocessed mel-spectrogram.\n",
    "        mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    " \n",
    "    # Segmemt mel-spectrogram into \"segment_len\" frames.\n",
    "        if len(mel) > self.segment_len:\n",
    "      # Randomly get the starting point of the segment.\n",
    "            start = random.randint(0, len(mel) - self.segment_len)\n",
    "      # Get a segment with \"segment_len\" frames.\n",
    "            mel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
    "        else:\n",
    "            mel = torch.FloatTensor(mel)\n",
    "    # Turn the speaker id into long for computing loss later.\n",
    "        speaker = torch.FloatTensor([speaker]).long()\n",
    "        return mel, speaker\n",
    "    \n",
    "    def get_speaker_number(self):\n",
    "        return self.speaker_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "  # Process features within a batch.\n",
    " \n",
    "    mel, speaker = zip(*batch)\n",
    "  # Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n",
    "    mel = pad_sequence(mel, batch_first=True, padding_value=-20)    # pad log 10^(-20) which is very small value.\n",
    "  # mel: (batch size, length, 40)\n",
    "    return mel, torch.FloatTensor(speaker).long()\n",
    "\n",
    "\n",
    "def get_dataloader(data_dir, batch_size, n_workers):\n",
    "    \n",
    "    dataset = myDataset(data_dir)\n",
    "    speaker_num = dataset.get_speaker_number()\n",
    "  # Split dataset into training dataset and validation dataset\n",
    "    trainlen = int(0.9 * len(dataset))\n",
    "    \n",
    "    lengths = [trainlen, len(dataset) - trainlen]\n",
    "    trainset, validset = random_split(dataset, lengths)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch,\n",
    "  )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "    validset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=n_workers,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch,\n",
    "  )\n",
    "    print(\"train_set:\",len(trainset),\"valid_set:\",len(validset))\n",
    "    return train_loader, valid_loader, speaker_num\n",
    "\n",
    "\n",
    "train_loader,valid_loader,speaker_num=get_dataloader(\"/kaggle/input/dataset2/Dataset\",32,2)\n",
    "print(\"speaker_num:\",speaker_num)\n",
    "# trainloader shape:[32,128,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T04:19:05.804909Z",
     "iopub.status.busy": "2023-01-06T04:19:05.804148Z",
     "iopub.status.idle": "2023-01-06T04:19:05.821558Z",
     "shell.execute_reply": "2023-01-06T04:19:05.820401Z",
     "shell.execute_reply.started": "2023-01-06T04:19:05.804867Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "#swish\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * x.sigmoid()\n",
    "\n",
    "#conformer block\n",
    "class ConformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #feed forward module\n",
    "        self.ff=nn.Sequential(\n",
    "            nn.LayerNorm(80),\n",
    "            nn.Linear(80,320),\n",
    "            Swish(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(320,80),\n",
    "            Swish(),\n",
    "            nn.Dropout(p=0.1)\n",
    "        )\n",
    "        #self attention module\n",
    "        self.atten=nn.TransformerEncoderLayer(\n",
    "      d_model=80, dim_feedforward=256, nhead=1,dropout=0.1\n",
    "    ) \n",
    "        #convolution model\n",
    "        self.conv=nn.Sequential(\n",
    "            # x : (batch size, length, d_model)\n",
    "            nn.LayerNorm(80),\n",
    "            Rearrange('b n c -> b c n'),\n",
    "            # x : (batch size, d_model, length)\n",
    "            nn.Conv1d(80,160,1,1),\n",
    "            nn.GLU(dim=1),\n",
    "            Rearrange('b c n -> b n c'),\n",
    "            # x : (batch size, length, d_model)\n",
    "            nn.Conv1d(128,128,1,1),\n",
    "            Rearrange('b n c -> b c n'),\n",
    "            # x : (batch size, d_model, length)\n",
    "            nn.BatchNorm1d(80),\n",
    "            Swish(),\n",
    "            nn.Conv1d(80,80,1,1),\n",
    "            Rearrange('b c n -> b n c'),\n",
    "            # x : (batch size, d_model, length)\n",
    "            nn.Dropout(p=0.1)\n",
    "        )\n",
    "        #layernorm\n",
    "        self.norm = nn.LayerNorm(80)\n",
    "    def forward(self,x):\n",
    "        x=0.5*self.ff(x)+x\n",
    "        x=self.atten(x).transpose(0, 1)+x.transpose(0, 1)\n",
    "        # x : (batch size, length, d_model)\n",
    "        x=self.conv(x)+x\n",
    "        x=0.5*self.ff(x)+x\n",
    "        x=self.norm(x)\n",
    "        return x\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, d_model=80, n_spks=600, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.prenet = nn.Linear(40, d_model)\n",
    "\n",
    "        self.conformer=ConformerBlock()\n",
    "    \n",
    "        self.pred_layer = nn.Sequential(\n",
    "                     nn.Linear(d_model, n_spks),\n",
    "                      )\n",
    "\n",
    "    def forward(self, mels):\n",
    "        \n",
    "        out = self.prenet(mels)\n",
    "        # out: (batch size, length, d_model)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        # out: (length, batch size, d_model)\n",
    "        out = self.conformer(out)\n",
    "        # out: (batch size, length, d_model)\n",
    "        \n",
    "        stats = out.mean(dim=1)\n",
    "        \n",
    "        # out: (batch, n_spks)\n",
    "        out = self.pred_layer(stats)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T04:19:07.414051Z",
     "iopub.status.busy": "2023-01-06T04:19:07.413230Z",
     "iopub.status.idle": "2023-01-06T04:19:07.422787Z",
     "shell.execute_reply": "2023-01-06T04:19:07.421461Z",
     "shell.execute_reply.started": "2023-01-06T04:19:07.414015Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "def get_cosine_schedule_with_warmup(\n",
    "        optimizer: Optimizer,\n",
    "        num_warmup_steps: int,\n",
    "        num_training_steps: int,\n",
    "        num_cycles: float = 0.5,\n",
    "        last_epoch: int = -1\n",
    "):\n",
    "    def lr_lambda(current_step):\n",
    "        # warmup\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        # decadence\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
    "\n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T04:19:08.917854Z",
     "iopub.status.busy": "2023-01-06T04:19:08.917502Z",
     "iopub.status.idle": "2023-01-06T04:19:08.927120Z",
     "shell.execute_reply": "2023-01-06T04:19:08.926066Z",
     "shell.execute_reply.started": "2023-01-06T04:19:08.917824Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def model_fn(batch, model, criterion, device):\n",
    "  \n",
    "    mels, labels = batch\n",
    "    mels = mels.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outs = model(mels)\n",
    "\n",
    "    loss = criterion(outs, labels)\n",
    "\n",
    "  # Get the speaker id with highest probability.\n",
    "    preds = outs.argmax(1)\n",
    "  # Compute accuracy.\n",
    "    accuracy = torch.mean((preds == labels).float())\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "def valid(dataloader, model, criterion, device): \n",
    "  \n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "   \n",
    "    for i, batch in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += accuracy.item()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return running_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T06:01:22.833644Z",
     "iopub.status.busy": "2023-01-06T06:01:22.832808Z",
     "iopub.status.idle": "2023-01-06T06:55:40.534666Z",
     "shell.execute_reply": "2023-01-06T06:55:40.533387Z",
     "shell.execute_reply.started": "2023-01-06T06:01:22.833571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n",
      "train_set: 62494 valid_set: 6944\n",
      "[Info]: Finish loading data!\n",
      "[Info]: Finish creating model!\n",
      "1 /100,train_acc: 0.04265625\n",
      "val_acc: 0.10555875576036866\n",
      "2 /100,train_acc: 0.1755\n",
      "val_acc: 0.2436635944700461\n",
      "3 /100,train_acc: 0.2845625\n",
      "val_acc: 0.3201324884792627\n",
      "4 /100,train_acc: 0.34125\n",
      "val_acc: 0.388536866359447\n",
      "5 /100,train_acc: 0.39421875\n",
      "val_acc: 0.4099942396313364\n",
      "6 /100,train_acc: 0.4295625\n",
      "val_acc: 0.44772465437788017\n",
      "7 /100,train_acc: 0.4550625\n",
      "val_acc: 0.46327764976958524\n",
      "8 /100,train_acc: 0.48328125\n",
      "val_acc: 0.4870391705069124\n",
      "9 /100,train_acc: 0.50475\n",
      "val_acc: 0.5\n",
      "10 /100,train_acc: 0.516875\n",
      "val_acc: 0.5252016129032258\n",
      "11 /100,train_acc: 0.53609375\n",
      "val_acc: 0.536434331797235\n",
      "12 /100,train_acc: 0.551625\n",
      "val_acc: 0.5429147465437788\n",
      "13 /100,train_acc: 0.56503125\n",
      "val_acc: 0.5652361751152074\n",
      "14 /100,train_acc: 0.578375\n",
      "val_acc: 0.5734447004608295\n",
      "15 /100,train_acc: 0.5874375\n",
      "val_acc: 0.5891417050691244\n",
      "16 /100,train_acc: 0.59696875\n",
      "val_acc: 0.5859735023041475\n",
      "17 /100,train_acc: 0.60971875\n",
      "val_acc: 0.5910138248847926\n",
      "18 /100,train_acc: 0.6188125\n",
      "val_acc: 0.5944700460829493\n",
      "19 /100,train_acc: 0.62515625\n",
      "val_acc: 0.6175115207373272\n",
      "20 /100,train_acc: 0.63871875\n",
      "val_acc: 0.6244239631336406\n",
      "21 /100,train_acc: 0.64178125\n",
      "val_acc: 0.6298963133640553\n",
      "22 /100,train_acc: 0.65015625\n",
      "val_acc: 0.621831797235023\n",
      "23 /100,train_acc: 0.6534375\n",
      "val_acc: 0.6394009216589862\n",
      "24 /100,train_acc: 0.66440625\n",
      "val_acc: 0.6286002304147466\n",
      "25 /100,train_acc: 0.66453125\n",
      "val_acc: 0.6466013824884793\n",
      "26 /100,train_acc: 0.67478125\n",
      "val_acc: 0.6359447004608295\n",
      "27 /100,train_acc: 0.67965625\n",
      "val_acc: 0.6589861751152074\n",
      "28 /100,train_acc: 0.68571875\n",
      "val_acc: 0.659418202764977\n",
      "29 /100,train_acc: 0.6898125\n",
      "val_acc: 0.6535138248847926\n",
      "30 /100,train_acc: 0.7019375\n",
      "val_acc: 0.6683467741935484\n",
      "31 /100,train_acc: 0.7008125\n",
      "val_acc: 0.6702188940092166\n",
      "32 /100,train_acc: 0.7116875\n",
      "val_acc: 0.6761232718894009\n",
      "33 /100,train_acc: 0.70684375\n",
      "val_acc: 0.675979262672811\n",
      "34 /100,train_acc: 0.721125\n",
      "val_acc: 0.6792914746543779\n",
      "35 /100,train_acc: 0.7224375\n",
      "val_acc: 0.6792914746543779\n",
      "36 /100,train_acc: 0.72984375\n",
      "val_acc: 0.6964285714285714\n",
      "37 /100,train_acc: 0.7268125\n",
      "val_acc: 0.6877880184331797\n",
      "38 /100,train_acc: 0.73621875\n",
      "val_acc: 0.6860599078341014\n",
      "39 /100,train_acc: 0.735\n",
      "val_acc: 0.7044930875576036\n",
      "40 /100,train_acc: 0.7458125\n",
      "val_acc: 0.7088133640552995\n",
      "41 /100,train_acc: 0.7478125\n",
      "val_acc: 0.7125576036866359\n",
      "42 /100,train_acc: 0.75484375\n",
      "val_acc: 0.7023329493087558\n",
      "43 /100,train_acc: 0.75375\n",
      "val_acc: 0.7118375576036866\n",
      "val_acc: 0.7191820276497696\n",
      "45 /100,train_acc: 0.75459375\n",
      "val_acc: 0.7160138248847926\n",
      "46 /100,train_acc: 0.77084375\n",
      "val_acc: 0.7148617511520737\n",
      "47 /100,train_acc: 0.76871875\n",
      "val_acc: 0.7210541474654378\n",
      "48 /100,train_acc: 0.77221875\n",
      "val_acc: 0.7243663594470046\n",
      "49 /100,train_acc: 0.778\n",
      "val_acc: 0.7370391705069125\n",
      "50 /100,train_acc: 0.77971875\n",
      "val_acc: 0.7285426267281107\n",
      "51 /100,train_acc: 0.78603125\n",
      "val_acc: 0.7435195852534562\n",
      "52 /100,train_acc: 0.78828125\n",
      "val_acc: 0.7295506912442397\n",
      "53 /100,train_acc: 0.788625\n",
      "val_acc: 0.7423675115207373\n",
      "54 /100,train_acc: 0.7928125\n",
      "val_acc: 0.7432315668202765\n",
      "55 /100,train_acc: 0.798375\n",
      "val_acc: 0.7484158986175116\n",
      "56 /100,train_acc: 0.79996875\n",
      "val_acc: 0.7459677419354839\n",
      "57 /100,train_acc: 0.80234375\n",
      "val_acc: 0.7595046082949308\n",
      "58 /100,train_acc: 0.80890625\n",
      "val_acc: 0.7481278801843319\n",
      "59 /100,train_acc: 0.80853125\n",
      "val_acc: 0.7517281105990783\n",
      "60 /100,train_acc: 0.81553125\n",
      "val_acc: 0.7613767281105991\n",
      "61 /100,train_acc: 0.8136875\n",
      "val_acc: 0.7527361751152074\n",
      "62 /100,train_acc: 0.82053125\n",
      "val_acc: 0.7595046082949308\n",
      "63 /100,train_acc: 0.82540625\n",
      "val_acc: 0.7645449308755761\n",
      "64 /100,train_acc: 0.8220625\n",
      "val_acc: 0.7655529953917051\n",
      "65 /100,train_acc: 0.830875\n",
      "val_acc: 0.7655529953917051\n",
      "66 /100,train_acc: 0.8301875\n",
      "val_acc: 0.7720334101382489\n",
      "67 /100,train_acc: 0.8316875\n",
      "val_acc: 0.7741935483870968\n",
      "68 /100,train_acc: 0.83403125\n",
      "val_acc: 0.7645449308755761\n",
      "69 /100,train_acc: 0.83865625\n",
      "val_acc: 0.7703052995391705\n",
      "70 /100,train_acc: 0.83746875\n",
      "val_acc: 0.7684331797235023\n",
      "71 /100,train_acc: 0.84475\n",
      "val_acc: 0.7741935483870968\n",
      "72 /100,train_acc: 0.842\n",
      "val_acc: 0.7783698156682027\n",
      "73 /100,train_acc: 0.84759375\n",
      "val_acc: 0.7800979262672811\n",
      "74 /100,train_acc: 0.84853125\n",
      "val_acc: 0.7800979262672811\n",
      "75 /100,train_acc: 0.8519375\n",
      "val_acc: 0.779089861751152\n",
      "76 /100,train_acc: 0.84953125\n",
      "val_acc: 0.7867223502304147\n",
      "77 /100,train_acc: 0.85478125\n",
      "val_acc: 0.7816820276497696\n",
      "78 /100,train_acc: 0.85571875\n",
      "val_acc: 0.7772177419354839\n",
      "79 /100,train_acc: 0.86115625\n",
      "val_acc: 0.7825460829493087\n",
      "80 /100,train_acc: 0.85975\n",
      "val_acc: 0.7874423963133641\n",
      "81 /100,train_acc: 0.861875\n",
      "val_acc: 0.7996831797235023\n",
      "82 /100,train_acc: 0.863875\n",
      "val_acc: 0.7821140552995391\n",
      "83 /100,train_acc: 0.8663125\n",
      "val_acc: 0.8001152073732719\n",
      "84 /100,train_acc: 0.86446875\n",
      "val_acc: 0.7962269585253456\n",
      "85 /100,train_acc: 0.8705625\n",
      "val_acc: 0.7962269585253456\n",
      "86 /100,train_acc: 0.86715625\n",
      "val_acc: 0.7998271889400922\n",
      "87 /100,train_acc: 0.87040625\n",
      "val_acc: 0.7962269585253456\n",
      "88 /100,train_acc: 0.8746875\n",
      "val_acc: 0.7976670506912442\n",
      "89 /100,train_acc: 0.875\n",
      "val_acc: 0.7983870967741935\n",
      "90 /100,train_acc: 0.87359375\n",
      "val_acc: 0.7992511520737328\n",
      "91 /100,train_acc: 0.87375\n",
      "val_acc: 0.8034274193548387\n",
      "92 /100,train_acc: 0.873\n",
      "val_acc: 0.7933467741935484\n",
      "93 /100,train_acc: 0.875375\n",
      "val_acc: 0.8025633640552995\n",
      "94 /100,train_acc: 0.87928125\n",
      "val_acc: 0.8008352534562212\n",
      "95 /100,train_acc: 0.8784375\n",
      "val_acc: 0.7980990783410138\n",
      "96 /100,train_acc: 0.87496875\n",
      "val_acc: 0.7963709677419355\n",
      "97 /100,train_acc: 0.87834375\n",
      "val_acc: 0.8008352534562212\n",
      "98 /100,train_acc: 0.8794375\n",
      "val_acc: 0.794786866359447\n",
      "99 /100,train_acc: 0.8791875\n",
      "val_acc: 0.8029953917050692\n",
      "100 /100,train_acc: 0.87625\n",
      "val_acc: 0.8063076036866359\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    config = {\n",
    "    \"data_dir\": \"/kaggle/input/dataset2/Dataset\",\n",
    "    \"save_path\": \"model.ckpt\",\n",
    "    \"batch_size\": 32,\n",
    "    \"n_workers\": 8,\n",
    "    \"valid_steps\": 2000,\n",
    "    \"warmup_steps\": 1000,\n",
    "    \"save_steps\": 10000,\n",
    "    \"total_steps\": 100001,\n",
    "  }\n",
    "\n",
    "    return config\n",
    "\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "\n",
    "def main(\n",
    "  data_dir,\n",
    "  save_path,\n",
    "  batch_size,\n",
    "  n_workers,\n",
    "  valid_steps,\n",
    "  warmup_steps,\n",
    "  total_steps,\n",
    "  save_steps,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "    train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
    "    train_iterator = iter(train_loader)\n",
    "    print(f\"[Info]: Finish loading data!\",flush = True)\n",
    "\n",
    "    model = Classifier(n_spks=speaker_num).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "    print(f\"[Info]: Finish creating model!\",flush = True)\n",
    "\n",
    "    best_accuracy = -1.0\n",
    "    best_state_dict = None\n",
    "\n",
    "    \n",
    "    batch_accuracy=0.0\n",
    "    for step in range(total_steps):\n",
    "    # Get data\n",
    "        try:\n",
    "            batch = next(train_iterator)\n",
    "        except StopIteration:\n",
    "            train_iterator = iter(train_loader)\n",
    "            batch = next(train_iterator)\n",
    "\n",
    "        loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "        batch_loss = loss.item()\n",
    "        batch_accuracy += accuracy.item()\n",
    "        if(step%1000==0 and step!=0 ):\n",
    "            batch_accuracy/=1000\n",
    "            print(int(step/1000),\"/100,train_acc:\",batch_accuracy)\n",
    "            train_acc_list.append(batch_accuracy)\n",
    "            batch_accuracy=0\n",
    "            \n",
    "        \n",
    "    # Updata model\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Do validation\n",
    "        if step  % 1000 == 0 and step!=0 :\n",
    "            valid_accuracy = valid(valid_loader, model, criterion, device)\n",
    "            print(\"val_acc:\",valid_accuracy)\n",
    "            val_acc_list.append(valid_accuracy)\n",
    "            if valid_accuracy > best_accuracy:\n",
    "                best_accuracy = valid_accuracy\n",
    "                best_state_dict = model.state_dict()\n",
    "\n",
    "            \n",
    "    # Save the best model so far.\n",
    "        if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
    "            torch.save(best_state_dict, save_path)\n",
    "    plt.figure()\n",
    "    x=range(0,100)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    plt.plot(x,train_acc_list,color='g',label='train_acc')\n",
    "    plt.plot(x,val_acc_list,color='r',label='val_acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "if __name__ == \"__main__\":\n",
    "    main(**parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
